{
  "nbformat_minor": 0, 
  "nbformat": 4, 
  "cells": [
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "%matplotlib inline"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "\n# Non-parametric spatio-temporal statistics on EEG sensor data\n\n\nRun a non-parametric spatio-temporal cluster stats on EEG sensors\non the contrast faces vs. scrambled.\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "import os.path as op\nimport numpy as np\nfrom scipy import stats\nfrom scipy import spatial\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\nimport mne\nfrom mne.stats import permutation_cluster_1samp_test\nfrom mne.viz import plot_topomap\n\nfrom library.config import meg_dir"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Read all the data\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "exclude = [1, 5, 16]  # Excluded subjects\n\ncontrasts = list()\n\nfor subject_id in range(1, 20):\n    if subject_id in exclude:\n        continue\n    subject = \"sub%03d\" % subject_id\n    print(\"processing subject: %s\" % subject)\n    data_path = op.join(meg_dir, subject)\n    contrast = mne.read_evokeds(op.join(data_path, '%s-ave.fif' % subject),\n                                condition='contrast')\n    contrast.pick_types(meg=False, eeg=True)\n    contrast.apply_baseline((-0.2, 0.0))\n    contrasts.append(contrast)\n\ncontrast = mne.combine_evoked(contrasts, 'equal')"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Assemble the data and run the cluster stats on channel data\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "data = np.array([c.data for c in contrasts])\n\nn_permutations = 1  # number of permutations to run\n\n# set family-wise p-value\np_accept = 0.01\n\nconnectivity = None\ntail = 0.  # for two sided test\n\n# set cluster threshold\nppf = stats.t.ppf\np_thresh = p_accept / (1 + (tail == 0))\nn_samples = len(data)\nthreshold = -ppf(p_thresh, n_samples - 1)\nif np.sign(tail) < 0:\n    threshold = -threshold\n\n# Make a triangulation between EEG channels locations to\n# use as connectivity for cluster level stat\n# XXX : make a mne.channels.make_eeg_connectivity function\nlay = mne.channels.make_eeg_layout(contrast.info)\nneigh = spatial.Delaunay(lay.pos[:, :2]).vertices\nconnectivity = mne.surface.mesh_edges(neigh)\n\ndata = np.transpose(data, (0, 2, 1))  # transpose for clustering\n\ncluster_stats = permutation_cluster_1samp_test(\n    data, threshold=threshold, n_jobs=2, verbose=True, tail=1,\n    connectivity=connectivity, out_type='indices',\n    check_disjoint=True)\n\nT_obs, clusters, p_values, _ = cluster_stats\ngood_cluster_inds = np.where(p_values < p_accept)[0]\n\nprint(\"Good clusters: %s\" % good_cluster_inds)"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }, 
    {
      "source": [
        "Visualize the spatio-temporal clusters\n\n"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "execution_count": null, 
      "cell_type": "code", 
      "source": [
        "times = contrast.times * 1e3\ncolors = 'r', 'steelblue'\nlinestyles = '-', '--'\n\npos = mne.find_layout(contrast.info).pos\n\nT_obs_max = 5.\nT_obs_min = -T_obs_max\n\n# loop over significant clusters\nfor i_clu, clu_idx in enumerate(good_cluster_inds):\n    # unpack cluster information, get unique indices\n    time_inds, space_inds = np.squeeze(clusters[clu_idx])\n    ch_inds = np.unique(space_inds)\n    time_inds = np.unique(time_inds)\n\n    # get topography for T0 stat\n    T_obs_map = T_obs[time_inds, ...].mean(axis=0)\n\n    # get signals at significant sensors\n    signals = data[..., ch_inds].mean(axis=-1)\n    sig_times = times[time_inds]\n\n    # create spatial mask\n    mask = np.zeros((T_obs_map.shape[0], 1), dtype=bool)\n    mask[ch_inds, :] = True\n\n    # initialize figure\n    fig, ax_topo = plt.subplots(1, 1, figsize=(10, 3))\n    title = 'Cluster #{0}'.format(i_clu + 1)\n    fig.suptitle(title, fontsize=14)\n\n    # plot average test statistic and mark significant sensors\n    image, _ = plot_topomap(T_obs_map, pos, mask=mask, axes=ax_topo,\n                            vmin=T_obs_min, vmax=T_obs_max,\n                            show=False)\n\n    # advanced matplotlib for showing image with figure and colorbar\n    # in one plot\n    divider = make_axes_locatable(ax_topo)\n\n    # add axes for colorbar\n    ax_colorbar = divider.append_axes('right', size='5%', pad=0.05)\n    plt.colorbar(image, cax=ax_colorbar)\n    ax_topo.set_xlabel('Averaged T-map ({:0.1f} - {:0.1f} ms)'.format(\n        *sig_times[[0, -1]]\n    ))\n\n    # add new axis for time courses and plot time courses\n    ax_signals = divider.append_axes('right', size='300%', pad=1.2)\n    for signal, name, col, ls in zip(signals, ['Contrast'], colors,\n                                     linestyles):\n        ax_signals.plot(times, signal, color=col, linestyle=ls, label=name)\n\n    # add information\n    ax_signals.axvline(0, color='k', linestyle=':', label='stimulus onset')\n    ax_signals.set_xlim([times[0], times[-1]])\n    ax_signals.set_xlabel('time [ms]')\n    ax_signals.set_ylabel('evoked [uV]')\n\n    # plot significant time range\n    ymin, ymax = ax_signals.get_ylim()\n    ax_signals.fill_betweenx((ymin, ymax), sig_times[0], sig_times[-1],\n                             color='orange', alpha=0.3)\n    ax_signals.legend(loc='lower right')\n    ax_signals.set_ylim(ymin, ymax)\n\n    # clean up viz\n    mne.viz.tight_layout(fig=fig)\n    fig.subplots_adjust(bottom=.05)\n    plt.show()"
      ], 
      "outputs": [], 
      "metadata": {
        "collapsed": false
      }
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2", 
      "name": "python2", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "2.7.12", 
      "pygments_lexer": "ipython2", 
      "codemirror_mode": {
        "version": 2, 
        "name": "ipython"
      }
    }
  }
}